# -*- coding: utf-8 -*-
"""BTech Project Sem 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15koxaQZfVJKrkHd-RzGzWdVS9He0Qt6L
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras import backend
from tensorflow.keras import layers
from tensorflow.keras import Model

import cv2
import numpy as np
import os
import math

import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.applications import *
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import joblib
from PIL import Image
from PIL import ImageFilter

import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import load_img
from keras.preprocessing import image

import concurrent.futures
import warnings
warnings.filterwarnings('ignore')

DATADIR= '/content/drive/MyDrive/ISRO Data_for CNN'
filepath= DATADIR+ '/metal.h5'
#model2_path=  DATADIR+ '/metal1.h5'
CATEGORIES = ['As-cast', 'Arc Welded', 'Additive Manufacturing', 'Electron beam processed']
IMG_SIZE=224
EPOCH=15

##sample image
for category in CATEGORIES:
    path=os.path.join(DATADIR, category)
    for img in os.listdir(path):
        img_array=cv2.imread(os.path.join(path,img))
        print(img_array.shape)
        #plt.title(path)
        plt.imshow(img_array)
        plt.show()
        break
    break

def whiteblack(img):
    wb = Image.fromarray(img.astype(np.uint8)).filter(ImageFilter.EDGE_ENHANCE)
    wb = wb.filter(ImageFilter.EDGE_ENHANCE)
    wb= np.asarray(wb, dtype='float32')
    wb = cv2.cvtColor(wb, cv2.COLOR_BGR2GRAY)
    wb = np.asarray(wb, dtype='float32')*(-1) + 255
    wb = cv2.fastNlMeansDenoising(wb.astype('uint8'), h=20, templateWindowSize=7, searchWindowSize=21)
    wb= cv2.bilateralFilter(wb.astype('uint8'), 3, 16, 4)
    wb = cv2.medianBlur(wb,3)
    return wb

def adaptivegauss(img):
    bw_1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    th3 = bw_1.astype('uint8')
    adapt_gauss = cv2.adaptiveThreshold(th3,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY,11,2)
    adapt_gauss = cv2.medianBlur(adapt_gauss,3)

    # print(adapt_gauss.shape)
    fig = plt.figure()
    plt.imshow(adapt_gauss)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/adapt_gauss.jpg', dpi = 500)

    return adapt_gauss

def seg32(img):
    bw_1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    th3 = bw_1.astype('uint8')
    bw_32seg = cv2.fastNlMeansDenoising(th3, None, h=5, templateWindowSize=7, searchWindowSize=21)
    for i in range(bw_32seg.shape[0]):
        for j in range(bw_32seg.shape[1]):
            if(bw_32seg[i, j]<32):
                bw_32seg[i, j]=0
            elif (bw_32seg[i, j]<64):
                bw_32seg[i, j]=32
            elif (bw_32seg[i, j]<32*3):
                bw_32seg[i, j]= 64
            elif (bw_32seg[i, j]<32*4):
                bw_32seg[i, j]=32*3
            elif (bw_32seg[i, j]<32*5):
                bw_32seg[i, j]=32*4
            elif (bw_32seg[i, j]<32*6):
                bw_32seg[i, j]=32*5
            elif (bw_32seg[i, j]<32*7):
                bw_32seg[i, j]=32*6
            elif (bw_32seg[i, j]<32*8):
                bw_32seg[i, j]=32*37
      
    # print(bw_32seg.shape)
    #fig = plt.figure()
    #plt.imshow(bw_32seg)
    #plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/bw_32seg.jpg', dpi = 500)
    
    return bw_32seg

def preprocess(img):
    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))
    img= np.asarray(img, dtype='float32')
    wb = whiteblack(img)
    image= np.tile(wb, (3, 1)).reshape(IMG_SIZE, IMG_SIZE, 3)
    adapt_gauss = adaptivegauss(img)
    seg_32= seg32(img)
    image[:, :, 0]= wb
    image[:, :, 1]= adapt_gauss
    image[:, :, 2]= seg_32
    image = (image/ 127.5) - 1

    # print(image.shape)
    fig = plt.figure()
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/preprocessed_image.jpg', dpi = 500)

    return image

def fill(img, h, w):
    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)
    return img
        
def horizontal_shift(img, ratio=0.2):
    ratio = random.uniform(-ratio, ratio)
    h, w = img.shape[:2]
    to_shift = w*ratio
    if ratio > 0:
        img = img[:, :int(w-to_shift), :]
    if ratio < 0:
        img = img[:, int(-1*to_shift):, :]
    img = fill(img, h, w)
    return img

def vertical_shift(img, ratio=0.2):
    if ratio > 1 or ratio < 0:
        print('Value should be less than 1 and greater than 0')
        return img
    ratio = random.uniform(-ratio, ratio)
    h, w = img.shape[:2]
    to_shift = h*ratio
    if ratio > 0:
        img = img[:int(h-to_shift), :, :]
    if ratio < 0:
        img = img[int(-1*to_shift):, :, :]
    img = fill(img, h, w)
    return img

def brightness(img, low=0.7, high=0.9):
    value = random.uniform(low, high)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    hsv = np.array(hsv, dtype = np.float64)
    hsv[:,:,1] = hsv[:,:,1]*value
    hsv[:,:,1][hsv[:,:,1]>255]  = 255
    hsv[:,:,2] = hsv[:,:,2]*value 
    hsv[:,:,2][hsv[:,:,2]>255]  = 255
    hsv = np.array(hsv, dtype = np.uint8)
    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    return img

def channel_shift(img, value=40):
    value = int(random.uniform(-value, value))
    img = img + value
    img[:,:,:][img[:,:,:]>255]  = 255
    img[:,:,:][img[:,:,:]<0]  = 0
    img = img.astype(np.uint8)
    return img

def erosion_image(image,shift=2):
    kernel = np.ones((shift,shift),np.uint8)
    image = cv2.erode(image,kernel,iterations = 1)
    return image


def black_hat_image(image, shift=200):
    kernel = np.ones((shift, shift), np.uint8)
    image = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)
    return image

def gausian_blur(image,blur=1.5):
    image = cv2.GaussianBlur(image,(5,5),blur)
    return image

def averageing_blur(image,shift=5):
    image=cv2.blur(image,(shift,shift))
    return image

def sharpen_image(image):
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    image = cv2.filter2D(image, -1, kernel)
    return image

'''def gaussian_noise(image, var=50):
    row,col,ch= image.shape
    image= np.asarray(image, dtype='float32')
    mean = 10
    sigma = var**0.5
    gauss = np.random.normal(mean,sigma,(row,col,ch))
    gauss = gauss.reshape(row,col,ch)
    noisy = image + gauss
    noisy = np.asarray(noisy, dtype='uint8')
    noisy = np.clip(noisy, 0, 255)
    return noisy
  
def salt_image(image,p=0.05,a=0.06):
    noisy=image
    num_salt = np.ceil(a * image.size * p)
    coords = [np.random.randint(0, i - 1, int(num_salt))
              for i in image.shape]
    noisy[coords] = 1
    return noisy
  
def contrast_image(image,contrast=30):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    image[:,:,2] = [[max(pixel - contrast, 0) if pixel < 190 else min(pixel + contrast, 255) for pixel in row] for row in image[:,:,2]]
    image= cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
    return image

'''

def fill(img, h, w):
    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)
    fig = plt.figure()
    plt.title('Fill')
    plt.imshow(img)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/fill.jpg', dpi = 500)

    return img
        
def horizontal_shift(img, ratio=0.2):
    ratio = random.uniform(-ratio, ratio)
    h, w = img.shape[:2]
    to_shift = w*ratio
    if ratio > 0:
        img = img[:, :int(w-to_shift), :]
    if ratio < 0:
        img = img[:, int(-1*to_shift):, :]
    img = fill(img, h, w)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Horizontal shift')
    plt.imshow(img)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/horizontal_shift.jpg', dpi = 500)

    return img

def vertical_shift(img, ratio=0.2):
    if ratio > 1 or ratio < 0:
        print('Value should be less than 1 and greater than 0')
        return img
    ratio = random.uniform(-ratio, ratio)
    h, w = img.shape[:2]
    to_shift = h*ratio
    if ratio > 0:
        img = img[:int(h-to_shift), :, :]
    if ratio < 0:
        img = img[int(-1*to_shift):, :, :]
    img = fill(img, h, w)
    
    # print(img.shape)
    fig = plt.figure()
    plt.title('Vertical shift')
    plt.imshow(img)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/vertical_shift.jpg', dpi = 500)

    return img

def brightness(img, low=0.7, high=0.9):
    value = random.uniform(low, high)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    hsv = np.array(hsv, dtype = np.float64)
    hsv[:,:,1] = hsv[:,:,1]*value
    hsv[:,:,1][hsv[:,:,1]>255]  = 255
    hsv[:,:,2] = hsv[:,:,2]*value 
    hsv[:,:,2][hsv[:,:,2]>255]  = 255
    hsv = np.array(hsv, dtype = np.uint8)
    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    # print(img.shape)
    fig = plt.figure()
    plt.title('Brightness')
    plt.imshow(img)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/brightness.jpg', dpi = 500)

    return img

def channel_shift(img, value=40):
    value = int(random.uniform(-value, value))
    img = img + value
    img[:,:,:][img[:,:,:]>255]  = 255
    img[:,:,:][img[:,:,:]<0]  = 0
    img = img.astype(np.uint8)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Channel Shift')
    plt.imshow(img)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/channel_shift.jpg', dpi = 500)

    return img

def erosion_image(image,shift=2):
    kernel = np.ones((shift,shift),np.uint8)
    image = cv2.erode(image,kernel,iterations = 1)
    
    # print(img.shape)
    fig = plt.figure()
    plt.title('Erosion Image')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/erosion_image.jpg', dpi = 500)

    return image


def black_hat_image(image, shift=200):
    kernel = np.ones((shift, shift), np.uint8)
    image = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Black hat image')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/black_hat_shift.jpg', dpi = 500)

    return image

def gausian_blur(image,blur=1.5):
    image = cv2.GaussianBlur(image,(5,5),blur)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Gaussian Blur')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/gaussian_blur.jpg', dpi = 500)
    

    return image

def averageing_blur(image,shift=5):
    image=cv2.blur(image,(shift,shift))
    # print(img.shape)
    fig = plt.figure()
    plt.title('Averaging blur')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/averaging_shift.jpg', dpi = 500)

    return image

def sharpen_image(image):
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    image = cv2.filter2D(image, -1, kernel)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Sharpened image')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/sharpen_image.jpg', dpi = 500)

    return image

def gaussian_noise(image, var=50):
    row,col,ch= image.shape
    image= np.asarray(image, dtype='float32')
    mean = 10
    sigma = var**0.5
    gauss = np.random.normal(mean,sigma,(row,col,ch))
    gauss = gauss.reshape(row,col,ch)
    noisy = image + gauss
    noisy = np.asarray(noisy, dtype='uint8')
    noisy = np.clip(noisy, 0, 255)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Gaussian Noise')
    plt.imshow(noisy)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/gaussian_noise.jpg', dpi = 500)

    return noisy
  
def salt_image(image,p=0.05,a=0.06):
    noisy=image
    num_salt = np.ceil(a * image.size * p)
    coords = [np.random.randint(0, i - 1, int(num_salt))
              for i in image.shape]
    noisy[coords] = 1
    # print(img.shape)
    fig = plt.figure()
    plt.title('Salt image')
    plt.imshow(noisy)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/salt_image.jpg', dpi = 500)

    return noisy
  
def contrast_image(image,contrast=30):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    image[:,:,2] = [[max(pixel - contrast, 0) if pixel < 190 else min(pixel + contrast, 255) for pixel in row] for row in image[:,:,2]]
    image= cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
    # print(img.shape)
    fig = plt.figure()
    plt.title('Contrast image')
    plt.imshow(image)
    plt.show()
    #fig.savefig('/content/drive/MyDrive/Sreekar data/Classification work/Augmented/new/contrast_image.jpg', dpi = 500)

    return image

path=os.path.join('/content/drive/MyDrive/ISRO Data_for CNN/validation/Image analysis Verification/As-cast','Object1.bmp' )

img_array = cv2.imread(path)
#print(img_array)
preprocessed = preprocess((img_array))
new_array1=vertical_shift(img_array)
new_array2=horizontal_shift(img_array)
new_array3=channel_shift(img_array)
new_array4=brightness(img_array)
new_array5=gausian_blur(img_array)
new_array6=erosion_image(img_array)
new_array7=black_hat_image(img_array)
new_array8=averageing_blur(img_array)
new_array9=sharpen_image(img_array)
new_array10=gaussian_noise(img_array)
new_array11=salt_image(img_array)
new_array12=contrast_image(img_array)

path=os.path.join('/content/drive/MyDrive/ISRO Data_for CNN/validation/Image analysis Verification/Electron beam processed','A (13).bmp' )

img_array = cv2.imread(path)
#print(img_array)
preprocessed = preprocess((img_array))
new_array3=channel_shift(img_array)
new_array4=brightness(img_array)
new_array5=gausian_blur(img_array)

training_data=[]
def create_training_data():
    for category in CATEGORIES:
        path=os.path.join(DATADIR, category)
        class_num=CATEGORIES.index(category)
        for img in os.listdir(path):
            try:
                img_array=cv2.imread(os.path.join(path,img))
                new_array2=preprocess((img_array))
                new_array3=preprocess(channel_shift(img_array))
                new_array4=preprocess(brightness(img_array))
                new_array5=preprocess(gausian_blur(img_array))
                training_data.append([new_array3,class_num])
                training_data.append([new_array2,class_num])
                training_data.append([new_array4,class_num])
                training_data.append([new_array5,class_num])
                training_data.append([flip_both,class_num])
            except:
                pass
create_training_data()

lenofdata = len(training_data)
print(lenofdata)

X=[]
y=[]

for categories, label in training_data:
    X.append(categories)
    y.append(label)
X= np.asarray(X, dtype= 'float32')
y=np.array(y)
print(y.shape)
print(X.shape)

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=101)

def conv_block(x, growth_rate, name):
  """A building block for a dense block.
  Args:
    x: input tensor.
    growth_rate: float, growth rate at dense layers.
    name: string, block label.
  Returns:
    Output tensor for the block.
  """
  bn_axis = 3
  x1 = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(x)
  x1 = layers.Activation('relu', name=name + '_0_relu')(x1)
  x1 = layers.Conv2D(
      4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(x1)
  x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(
          x1)
  x1 = layers.Activation('relu', name=name + '_1_relu')(x1)
  x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(
          x1)
  x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])
  return x

def transition_block(x, reduction, name):
  """A transition block.
  Args:
    x: input tensor.
    reduction: float, compression rate at transition layers.
    name: string, block label.
  Returns:
    output tensor for the block.
  """
  bn_axis = 3 
  x = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(
          x)
  x = layers.Activation('relu', name=name + '_relu')(x)
  x = layers.Conv2D(
      int(backend.int_shape(x)[bn_axis] * reduction),
      1,
      use_bias=False,
      name=name + '_conv')(
          x)
  x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)
  return x

def dense_block(x, blocks, name):
  
  for i in range(blocks):
    x = conv_block(x, 12, name=name + '_block' + str(i + 1))   # original= conv_block(x, 32, name=name + '_block' + str(i + 1))
  x= layers.Dropout((blocks/100), name= name+'_drop')(x)      # wasnt there
  return x

def DenseNet(
    blocks= [3, 6, 12, 8],    
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'):
  
  if input_tensor is None:
    img_input = layers.Input(shape=input_shape)
  else:
    if not backend.is_keras_tensor(input_tensor):
      img_input = layers.Input(tensor=input_tensor, shape=input_shape)
    else:
      img_input = input_tensor

  bn_axis = 3

  x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)
  x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)
  x = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(
          x)
  x = layers.Activation('relu', name='conv1/relu')(x)
  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)
  x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)

  x = dense_block(x, blocks[0], name='conv2')
  x = transition_block(x, 0.5, name='pool2')
  x = dense_block(x, blocks[1], name='conv3')
  x = transition_block(x, 0.5, name='pool3')
  x = dense_block(x, blocks[2], name='conv4')
  x = transition_block(x, 0.5, name='pool4')
  x = dense_block(x, blocks[3], name='conv5')

  x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)
  x = layers.Activation('relu', name='relu')(x)
  x = layers.GlobalAveragePooling2D(name='avg_pool')(x)
  x= layers.Flatten()(x)
  x= layers.Dense(216, activation='elu', name='penultimate_dense')(x)
  x = layers.Dropout(0.3)(x)
  x= layers.Dense(6, activation='softmax', name='output_layer')(x)

  # Ensure that the model takes into account
  # any potential predecessors of `input_tensor`.
  inputs = img_input

  model = Model(inputs, x, name='deepMetal')
  
  return model

model= DenseNet(input_shape=(IMG_SIZE, IMG_SIZE, 3))
model.summary()

model.compile(optimizer = Adam(lr=2e-4), loss='sparse_categorical_crossentropy', metrics=['acc'])

correct = 0
for i in range(len(y_test)) :
  preds = model.predict(X_test[i].reshape(1,IMG_SIZE, IMG_SIZE, 3 ))
  if(np.argmax(np.asarray(preds))== y_test[i]):
    #print (np.argmax(np.asarray(preds)), y_test[i])
    correct += 1
p = (correct*100/len(y_test))
print(f'Prediction accuracy = {p} %')

my_callbacks = [
  ReduceLROnPlateau(
    monitor='val_loss', factor=0.75, patience=2, verbose=True,
    mode='min', min_delta=0.000001, cooldown=0, min_lr=0 
  ), 
  ModelCheckpoint(
    filepath, monitor='val_acc', verbose=1, save_best_only=True, mode= 'max')]

regularizer = tf.keras.regularizers.l2(0.01)
for lay in model.layers:
    for attr in ['kernel_regularizer']:
        if hasattr(lay, attr):
          setattr(lay, attr, regularizer)

#model = history
predictions = np.empty(len(y_test), dtype=int)
for i in range(len(y_test)):
  pred = model.predict(X_test[i].reshape(1,IMG_SIZE, IMG_SIZE, 3 ))
  #print (pred)
  predictions[i] = np.argmax(np.asarray(pred))
  #print(predictions[i])
  
cm = confusion_matrix(y_test,predictions)

import seaborn as sn
plt.figure(figsize=(10,8))
sn.heatmap(cm, annot=True, cmap='Blues')
plt.xlabel('Prediction')
plt.ylabel('Truth')

history = model.fit(X_train, y_train,
                    shuffle = True,
                    epochs=50,
                    workers = 8,
                    steps_per_epoch= 256,
                    verbose=True,
                    use_multiprocessing=True,
                    validation_data=(X_test, y_test),
                    callbacks=my_callbacks)

import joblib
#joblib.dump(model,'trained_model')

history = joblib.load('/content/drive/MyDrive/ISRO Data_for CNN/trained_model')

acc = history.history['acc']
val_acc = history.history['val_acc']

loss = history.history['loss']
val_loss = history.history['val_loss']
axis_font = {'fontname':'Arial', 'size':'200'}

plt.rcParams['font.size'] = '130'
plt.rcParams['axes.linewidth'] = 10
plt.figure(figsize=(140, 125))
plt.plot(loss, label='Training Loss',linewidth=15)
plt.plot(val_loss, label='Validation Loss',color='black',linewidth=15, linestyle="--")
plt.xlabel('Epochs')
plt.legend(loc='upper right')
plt.xlabel('Epochs', labelpad=100, **axis_font)
plt.ylabel('Categorical Crossentropy Loss', labelpad=100, **axis_font)
plt.ylim([0,max(plt.ylim())])
# plt.title('Training and Validation Loss')
plt.show()
plt.savefig('/content/drive/MyDrive/ISRO Data_for CNN/Crossentropyloss.jpg')

acc = history.history['acc']
val_acc = history.history['val_acc']

loss = history.history['loss']
val_loss = history.history['val_loss']
axis_font = {'fontname':'Arial', 'size':'200'}

plt.rcParams['font.size'] = '130'
fig = plt.figure(figsize=(140, 100))
plt.rcParams['axes.linewidth'] = 10
# plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy',linewidth=15)
plt.plot(val_acc, label='Validation Accuracy',color='black',linewidth=15, linestyle="--")
plt.legend(loc='lower right')
plt.ylabel('Accuracy', labelpad=100, **axis_font)
plt.xlabel('Epochs', labelpad=100, **axis_font)
plt.ylim([min(plt.ylim()),1])
# plt.title('Training and Validation Accuracy', **axis_font)
plt.show(block=True)
fig.savefig('/content/drive/MyDrive/ISRO Data_for CNN/accuary.jpg', dpi = 300)

# for lay in model.layers:
#     for attr in ['kernel_regularizer']:
#         if hasattr(lay, attr):
#           setattr(lay, attr, None)

# for lay in model.layers:
#   lay.trainable= False

# for lay in model.layers[:(len(model.layers))//3]:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//3,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

# for lay in model.layers:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//4,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

# for lay in model.layers:
#   lay.trainable= False

# for lay in model.layers[(len(model.layers))//3 : 2*(len(model.layers))//3 ]:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//3,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

# for lay in model.layers:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//4,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

# for lay in model.layers:
#   lay.trainable= False

# for lay in model.layers[ 2*(len(model.layers))//3 : ]:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//3,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

# for lay in model.layers:
#   lay.trainable= True

# history = model.fit(X_train, y_train,
#                     shuffle = True,
#                     epochs=EPOCH//4,
#                     workers = 8,
#                     verbose=True,
#                     use_multiprocessing=True,
#                     validation_data=(X_test, y_test),
#                     callbacks=my_callbacks)

'''
models=[]
models.append(tf.keras.load_model(filepath))
models.append(tf.keras.load_model(model2_path))
weights = [model.get_weights() for model in models]
new_weights = list()

for weights_list_tuple in zip(*weights):
    new_weights.append(
        [numpy.array(weights_).mean(axis=0)\
            for weights_ in zip(*weights_list_tuple)])

model.set_weights(new_weights)
'''

path=os.path.join('/content/drive/MyDrive/ISRO Data_for CNN/validation/Image analysis Verification/Arc Welded','Object1.bmp')
img_array=cv2.imread(path)
print(img_array)

path=os.path.join('/content/drive/MyDrive/ISRO Data_for CNN/validation/Image analysis Verification/Arc Welded','Object3.bmp')
img_array=cv2.imread(path)
img_array1 = cv2.cvtColor(np.asarray(img_array, dtype='uint8'), cv2.COLOR_BGR2RGB)
plt.figure(figsize=((10, 10)))
print(img_array.shape)
plt.imshow(img_array1)
plt.axis('off')
plt.show()

model = history
layer_names= ['input_1', 'pool1', 'pool2_pool', 'pool3_pool', 'pool4_pool', 'conv5_drop']
results = Model(model.inputs, [model.get_layer(lay).output for lay in layer_names]) 
input_data = preprocess(img_array).reshape(1, IMG_SIZE, IMG_SIZE, 3)
result = model.predict(input_data)
results = results.predict(input_data)
#print ([result[i].shape for i in range(len(result))])
print(CATEGORIES[np.argmax(result)])

#results.shape

"""**TESTING AGAINST VALIDATION INPUT DATA**"""

#Start with data processing and then validate it by tomorrow

validation_data=[]
def create_validation_data():
    for category in CATEGORIES:
        path=os.path.join('/content/drive/MyDrive/ISRO Data_for CNN/validation/Image analysis Verification', category)
        class_num=CATEGORIES.index(category)
        for img in os.listdir(path):
            try:
                img_array=cv2.imread(os.path.join(path,img))
                new_array2=preprocess((img_array))
                new_array3=preprocess(channel_shift(img_array))
                new_array4=preprocess(brightness(img_array))
                new_array5=preprocess(gausian_blur(img_array))
                validation_data.append([new_array3,class_num])
                validation_data.append([new_array2,class_num])
                validation_data.append([new_array4,class_num])
                validation_data.append([new_array5,class_num])
                validation_data.append([flip_both,class_num])
            except:
                pass
create_validation_data()

len(validation_data)

X=[]
y=[]

for categories, label in validation_data:
    X.append(categories)
    y.append(label)
X= np.asarray(X, dtype= 'float32')
y=np.array(y)
print(y.shape)
print(X.shape)

model = history
predictions = np.empty(len(X), dtype=int)
for i in range(len(X)):
  pred = model.predict(X[i].reshape(1,IMG_SIZE, IMG_SIZE, 3 ))
  #print (pred)
  predictions[i] = np.argmax(np.asarray(pred))
  #print(predictions[i])
  
cm = confusion_matrix(y,predictions)

import seaborn as sn
plt.figure(figsize=(10,8))
sn.heatmap(cm, annot=True, cmap='Blues')
if CATEGORIES is not None:
        tick_marks = np.arange(len(CATEGORIES))
        plt.xticks(tick_marks, CATEGORIES, rotation=45)
        plt.yticks(tick_marks, CATEGORIES, rotation=0)
plt.xlabel('Prediction')
plt.ylabel('Truth')

correct = 0
for i in range(len(X)) :
  preds = model.predict(X[i].reshape(1,IMG_SIZE, IMG_SIZE, 3 ))
  if(np.argmax(np.asarray(preds))== y[i]):
    #print (np.argmax(np.asarray(preds)), y_test[i])
    correct += 1
p = (correct*100/len(y))
print(f'Prediction accuracy = {p} %')

#pip install scipy

model = history
model.summary()

pip install tf-keras-vis tensorflow

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2

import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline

import tensorflow as tf
from tf_keras_vis.utils import num_of_gpus

_, gpus = num_of_gpus()
print('Tensorflow recognized {} GPUs'.format(gpus))

from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.applications.vgg16 import preprocess_input

# Image titles
image_titles = ['Additive Manufacturing', 'Arc Welded', 'Electron beam processed', 'As-cast']

# Load images and Convert them to a Numpy array
img1 = load_img('/content/drive/MyDrive/ISRO Data_for CNN/Object1.bmp', target_size=(224, 224))
img2 = load_img('/content/drive/MyDrive/ISRO Data_for CNN/Object2.bmp', target_size=(224, 224))
img3 = load_img('/content/drive/MyDrive/ISRO Data_for CNN/Object3.bmp', target_size=(224, 224))
img4 = load_img('/content/drive/MyDrive/ISRO Data_for CNN/Object4.bmp', target_size=(224, 224))
images = np.asarray([np.array(img1), np.array(img2), np.array(img3), np.array(img4)])

# Preparing input data for VGG16
X = preprocess_input(images)

# Rendering
f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))
for i, title in enumerate(image_titles):
    ax[i].set_title(title, fontsize=16)
    ax[i].imshow(images[i])
    ax[i].axis('off')
plt.tight_layout()
plt.show()

from tf_keras_vis.utils.model_modifiers import ReplaceToLinear

replace2linear = ReplaceToLinear()

# Instead of using the ReplaceToLinear instance above,
# you can also define the function from scratch as follows:
def model_modifier_function(cloned_model):
    cloned_model.layers[-1].activation = tf.keras.activations.linear

from tf_keras_vis.utils.scores import CategoricalScore

# 1 is the imagenet index corresponding to Goldfish, 294 to Bear and 413 to Assault Rifle.
score = CategoricalScore([0,1,2,3])

# Instead of using CategoricalScore object,
# you can also define the function from scratch as follows:
def score_function(output):
    # The `output` variable refers to the output of the model,
    # so, in this case, `output` shape is `(3, 1000)` i.e., (samples, classes).
    return (output[0][0], output[1][1], output[2][2], output[3][3])

model = history
from tensorflow.keras import backend as K
from tf_keras_vis.saliency import Saliency
# from tf_keras_vis.utils import normalize

# Create Saliency object.
saliency = Saliency(model,
                    model_modifier=replace2linear,
                    clone=True)

# Generate saliency map
saliency_map = saliency(score, X)

## Since v0.6.0, calling `normalize()` is NOT necessary.
# saliency_map = normalize(saliency_map)

# Render
f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))
for i, title in enumerate(image_titles):
    ax[i].set_title(title, fontsize=16)
    ax[i].imshow(saliency_map[i], cmap='jet')
    ax[i].axis('off')
plt.tight_layout()
plt.show()

from matplotlib import cm
from tf_keras_vis.gradcam import Gradcam

# Create Gradcam object
gradcam = Gradcam(model,
                  model_modifier=replace2linear,
                  clone=True)

# Generate heatmap with GradCAM
cam = gradcam(score,
             X,
              penultimate_layer=-1)

## Since v0.6.0, calling `normalize()` is NOT necessary.
# cam = normalize(cam)

# Render
f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))
for i, title in enumerate(image_titles):
    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)
    ax[i].set_title(title, fontsize=16)
    ax[i].imshow(images[i])
    ax[i].imshow(heatmap, cmap='jet', alpha=0.5) # overlay
    ax[i].axis('off')
plt.tight_layout()
plt.show()

#from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus

# Create GradCAM++ object
#gradcam = GradcamPlusPlus(model,
#                          model_modifier=replace2linear,
#                          clone=True)

# Generate heatmap with GradCAM++
#cam = gradcam(score,
#              X,
#              penultimate_layer=-1)

## Since v0.6.0, calling `normalize()` is NOT necessary.
# cam = normalize(cam)

# Render
#f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))
#for i, title in enumerate(image_titles):
#    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)
#    ax[i].set_title(title, fontsize=16)
#    ax[i].imshow(images[i])
#    ax[i].imshow(heatmap, cmap='jet', alpha=0.5)
#    ax[i].axis('off')
#plt.tight_layout()
#plt.savefig('images/gradcam_plus_plus.png')
#plt.show()